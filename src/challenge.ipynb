{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1: \n",
    "Las top 10 fechas donde hay m√°s tweets. Mencionar el usuario (username) que m√°s publicaciones tiene por cada uno de esos d√≠as. \n",
    "\n",
    "**Supuesto1:** Para cumplir con lo solicitado, se trabaja el USERNAME como id unico representante de una cuenta, pero, como regla de negocio esto es incorrecto, ya que un USERNAME en twitter puede cambiar para una misma cuenta.\n",
    "\n",
    "## Ejecucion1 optimizada para Tiempo ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "ERROR: Could not find file C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_8176\\681458841.py\n",
      "Filename: c:\\Users\\Usuario\\Downloads\\challenge_DE\\src\\q1_time.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    16    154.0 MiB    154.0 MiB           1   @profile\n",
      "    17                                         def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
      "    18    154.0 MiB      0.0 MiB           1       resp = []\n",
      "    19    154.0 MiB      0.0 MiB           1       pd.set_option('mode.chained_assignment', None)  # Levantar una excepci√≥n\n",
      "    20   1675.6 MiB   1521.6 MiB           1       pddf=pd.read_json(file_path, lines=True)\n",
      "    21   1633.5 MiB    -42.1 MiB           1       pddf=pddf[['date','url','user']] \n",
      "    22   1635.3 MiB      1.7 MiB           1       pddf['date_fecha'] = pddf['date'].dt.date\n",
      "    23                                         \n",
      "    24   1636.3 MiB      1.0 MiB           1       df_topdates = pddf.groupby('date_fecha').agg({'url': ['count']})\n",
      "    25   1636.3 MiB      0.0 MiB           1       df_topdates.columns = ['url_count']\n",
      "    26   1636.3 MiB      0.0 MiB           1       df_topdates = df_topdates.reset_index()\n",
      "    27   1636.3 MiB      0.0 MiB           1       df_topdates=df_topdates.sort_values(by='url_count', ascending=False)\n",
      "    28   1636.3 MiB      0.0 MiB           1       df_topdates = df_topdates.head(10)\n",
      "    29                                         \n",
      "    30                                         \n",
      "    31   1639.9 MiB      0.0 MiB          11       for indice, fila in df_topdates.iterrows():\n",
      "    32   1639.8 MiB      2.2 MiB          10           df_topuser_xdate = pddf[pddf['date_fecha'] == fila['date_fecha']]\n",
      "    33   1639.8 MiB      0.3 MiB      198744           df_topuser_xdate['identificador'] = df_topuser_xdate['user'].apply(lambda x: x['username'])\n",
      "    34   1639.8 MiB      0.7 MiB          10           df_topuser_xdate = df_topuser_xdate.groupby('identificador').agg({'url': ['count']})\n",
      "    35   1639.8 MiB      0.0 MiB          10           df_topuser_xdate=df_topuser_xdate.reset_index()\n",
      "    36   1639.8 MiB      0.0 MiB          10           df_topuser_xdate.columns = ['identificador','url_count']\n",
      "    37   1639.9 MiB      0.4 MiB          10           df_topuser_xdate=df_topuser_xdate.sort_values(by='url_count', ascending=False)\n",
      "    38   1639.9 MiB      0.0 MiB          10           df_topuser_xdate = df_topuser_xdate.head(1)\n",
      "    39   1639.9 MiB      0.0 MiB          10           resp.append((fila['date_fecha'],df_topuser_xdate['identificador'].values[0])) #\n",
      "    40                                         \n",
      "    41   1639.9 MiB      0.0 MiB           1       return resp\n",
      "\n",
      "\n",
      "         672858 function calls (671326 primitive calls) in 10.129 seconds\n",
      "\n",
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler\n",
    "\n",
    "import q1_time as q1t\n",
    "from memory_profiler import profile\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "@profile\n",
    "def try_stat():\n",
    "    profiler=cProfile.Profile()\n",
    "    profiler.enable()\n",
    "    li_q1t = q1t.q1_time('../../farmers-protest-tweets-2021-2-4.json')\n",
    "    profiler.disable()\n",
    "    stats = pstats.Stats(profiler)\n",
    "    stats.print_stats(0)\n",
    "    print(li_q1t)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try_stat()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultado\n",
    "[<br>\n",
    "  (datetime.date(2021, 2, 12), 'RanbirS00614606'), <br>\n",
    "  (datetime.date(2021, 2, 13), 'MaanDee08215437'),<br>\n",
    "  (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), <br>\n",
    "  (datetime.date(2021, 2, 16), 'jot__b'), <br>\n",
    "  (datetime.date(2021, 2, 14), 'rebelpacifist'), <br>\n",
    "  (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), <br>\n",
    "  (datetime.date(2021, 2, 15), 'jot__b'), <br>\n",
    "  (datetime.date(2021, 2, 20), 'MangalJ23056160'), <br>\n",
    "  (datetime.date(2021, 2, 23), 'Surrypuria'), <br>\n",
    "  (datetime.date(2021, 2, 19), 'Preetm91')<br>\n",
    "  ]<br>\n",
    " \n",
    "(t+) se aprecia que el consumo de memoria en cada instruccion es de ~1640MiB para casi todas las instrucciones del primer y segundo bloque, el tiempo es de  aproximados 10 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecucion1 optimizada para Memoria ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "ERROR: Could not find file C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_8176\\4294011426.py\n",
      "Filename: c:\\Users\\Usuario\\Downloads\\challenge_DE\\src\\q1_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    17    157.4 MiB    157.4 MiB           1   @profile\n",
      "    18                                         def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
      "    19    157.4 MiB      0.0 MiB           1       resp = []\n",
      "    20    157.4 MiB      0.0 MiB           1       pd.set_option('mode.chained_assignment', None)  # Levantar una excepci√≥n\n",
      "    21    157.4 MiB      0.0 MiB           1       with open(file_path, 'r') as f:\n",
      "    22    570.8 MiB -15426.6 MiB      117410           data = [[json.loads(line)['url'], pd.to_datetime(json.loads(line)['date']), json.loads(line)['user']['username']]  for line in f.readlines()]\n",
      "    23    438.5 MiB   -132.3 MiB           1       columnas = ['url', 'date', 'identificador']\n",
      "    24    440.4 MiB      1.9 MiB           1       pddf = pd.DataFrame(data, columns=columnas)\n",
      "    25    444.1 MiB      3.7 MiB           1       pddf['date_fecha'] = pddf['date'].dt.date\n",
      "    26                                         \n",
      "    27    444.2 MiB      0.1 MiB           1       df_topdates = pddf.groupby('date_fecha').agg({'url': ['count']})\n",
      "    28    444.2 MiB      0.0 MiB           1       df_topdates.columns = ['url_count']\n",
      "    29    444.2 MiB      0.0 MiB           1       df_topdates = df_topdates.reset_index()\n",
      "    30    444.2 MiB      0.0 MiB           1       df_topdates=df_topdates.sort_values(by='url_count', ascending=False)\n",
      "    31    444.2 MiB      0.0 MiB           1       df_topdates = df_topdates.head(10)\n",
      "    32                                         \n",
      "    33    444.2 MiB      0.0 MiB          11       for indice, fila in df_topdates.iterrows():\n",
      "    34    444.2 MiB    -27.3 MiB          10           df_topuser_xdate = pddf[pddf['date_fecha'] == fila['date_fecha']]\n",
      "    35                                                 #df_topuser_xdate['identificador'] = df_topuser_xdate['user'].apply(lambda x: x['username'])\n",
      "    36    441.2 MiB    -30.3 MiB          10           df_topuser_xdate = df_topuser_xdate.groupby('identificador').agg({'url': ['count']})\n",
      "    37    441.2 MiB      0.0 MiB          10           df_topuser_xdate=df_topuser_xdate.reset_index()\n",
      "    38    441.2 MiB      0.0 MiB          10           df_topuser_xdate.columns = ['identificador','url_count']\n",
      "    39    441.2 MiB      0.0 MiB          10           df_topuser_xdate=df_topuser_xdate.sort_values(by='url_count', ascending=False)\n",
      "    40    441.2 MiB      0.0 MiB          10           df_topuser_xdate = df_topuser_xdate.head(1)\n",
      "    41    441.2 MiB      0.0 MiB          10           resp.append((fila['date_fecha'],df_topuser_xdate['identificador'].values[0])) #\n",
      "    42                                         \n",
      "    43    441.2 MiB     -3.0 MiB           1       return resp\n",
      "\n",
      "\n",
      "         144211904 function calls (144093254 primitive calls) in 403.207 seconds\n",
      "\n",
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler\n",
    "\n",
    "import q1_memory as q1m\n",
    "from memory_profiler import profile\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "@profile\n",
    "def try_stat():\n",
    "    profiler=cProfile.Profile()\n",
    "    profiler.enable()\n",
    "    li_q1m = q1m.q1_memory('./farmers-protest-tweets-2021-2-4.json')\n",
    "    profiler.disable()\n",
    "    stats = pstats.Stats(profiler)\n",
    "    stats.print_stats(0)\n",
    "    print(li_q1m)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try_stat()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultado \n",
    "[<br>\n",
    "  (datetime.date(2021, 2, 12), 'RanbirS00614606'), <br>\n",
    "  (datetime.date(2021, 2, 13), 'MaanDee08215437'),<br>\n",
    "  (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), <br>\n",
    "  (datetime.date(2021, 2, 16), 'jot__b'), <br>\n",
    "  (datetime.date(2021, 2, 14), 'rebelpacifist'), <br>\n",
    "  (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), <br>\n",
    "  (datetime.date(2021, 2, 15), 'jot__b'), <br>\n",
    "  (datetime.date(2021, 2, 20), 'MangalJ23056160'), <br>\n",
    "  (datetime.date(2021, 2, 23), 'Surrypuria'), <br>\n",
    "  (datetime.date(2021, 2, 19), 'Preetm91')<br>\n",
    "  ]<br>\n",
    "  \n",
    "(m+) se aprecia que el consumo de memoria en cada instruccion del primer y segundo bloque es de aproximados ~440MiB. y en consecuencia, el tiempo subio considerablemente a aproximados ~403 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2: \n",
    "Los top 10 emojis m√°s usados con su respectivo conteo. \n",
    "\n",
    "**Supuesto1:** No tengo una definicion clara de que es un emoji, ya que tecnicamente un emoji es un caracter unicode representado por un \\u*, por lo que bajo esa definicion se trabajo la solucion.\n",
    "\n",
    "## Ejecucion2 optimizada para Tiempo ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "ERROR: Could not find file C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_8176\\1025412768.py\n",
      "Filename: c:\\Users\\Usuario\\Downloads\\challenge_DE\\src\\q2_time.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    17    430.2 MiB    430.2 MiB           1   @profile\n",
      "    18                                         def q2_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
      "    19    430.2 MiB      0.0 MiB           1       pd.set_option('mode.chained_assignment', None)  #evita warning\n",
      "    20                                             #cargo el jsonl como dataframe pandas\n",
      "    21   1665.7 MiB   1235.5 MiB           1       pddf=pd.read_json(file_path, lines=True)\n",
      "    22                                             #trabajo solo con una columna, la que hace referencia al body del tweet\n",
      "    23   1500.9 MiB   -164.8 MiB           1       pddf=pddf[['content']]     \n",
      "    24                                             # selecciono solo las filas que tengan al menos un emoji\n",
      "    25   1502.7 MiB      1.8 MiB           1       pddf = pddf[pddf['content'].str.contains(r'[\\U0001F300-\\U0001F5FF\\U0001F600-\\U0001F64F\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U00002702-\\U000027B0\\U000024C2-\\U0001F251\\U0001F004\\U0001F0CF\\U0001F170-\\U0001F251\\U0001F1E6-\\U0001F1FF]', regex=True)]\n",
      "    26                                             # elimino todo contenido que no sea un emoji\n",
      "    27   1502.8 MiB      0.1 MiB       33901       pddf['content'] = pddf['content'].apply(lambda x: ' '.join(re.findall(r'[\\U0001F300-\\U0001F5FF\\U0001F600-\\U0001F64F\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U00002702-\\U000027B0\\U000024C2-\\U0001F251\\U0001F004\\U0001F0CF\\U0001F170-\\U0001F251\\U0001F1E6-\\U0001F1FF]', x)))\n",
      "    28                                             # separo las celdas que tengan mas de un emoji en filas\n",
      "    29    246.7 MiB  -1256.2 MiB           1       pddf = pddf.assign(content=pddf['content'].str.split(' ')).explode('content').reset_index(drop=True)\n",
      "    30                                             # selecciono las filas que no sean vacias\n",
      "    31    246.7 MiB      0.0 MiB           1       pddf = pddf[pddf['content'] != ' ']\n",
      "    32                                             \n",
      "    33                                             # count de emojis\n",
      "    34    246.7 MiB      0.1 MiB           1       df_topemoji = pddf.groupby('content').agg({'content': ['count']})\n",
      "    35    246.7 MiB      0.0 MiB           1       df_topemoji = df_topemoji.reset_index()\n",
      "    36                                             # rename de columnas\n",
      "    37    246.7 MiB      0.0 MiB           1       df_topemoji.columns = ['content','emoji_count']\n",
      "    38                                             # orderno desc\n",
      "    39    246.7 MiB      0.0 MiB           1       df_topemoji=df_topemoji.sort_values(by='emoji_count', ascending=False)\n",
      "    40                                             # selecciono las top10\n",
      "    41    246.7 MiB      0.0 MiB           1       df_topemoji = df_topemoji.head(10)\n",
      "    42                                             # dataframe a lista de tuplas\n",
      "    43    246.7 MiB      0.0 MiB           1       list_topemoji = list(df_topemoji.to_records(index=False))\n",
      "    44    246.7 MiB      0.0 MiB           1       return list_topemoji\n",
      "\n",
      "\n",
      "         905398 function calls (904779 primitive calls) in 9.277 seconds\n",
      "\n",
      "[('üôè', 7286), ('üòÇ', 3072), ('Ô∏è', 3061), ('üöú', 2972), ('‚úä', 2411), ('üåæ', 2363), ('üáÆ', 2096), ('üá≥', 2094), ('üèª', 2080), ('‚ù§', 1779)]\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler\n",
    "\n",
    "import q2_time as q2t\n",
    "from memory_profiler import profile\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "@profile\n",
    "def try_stat():\n",
    "    profiler=cProfile.Profile()\n",
    "    profiler.enable()\n",
    "    li_q2t = q2t.q2_time('./farmers-protest-tweets-2021-2-4.json')\n",
    "    profiler.disable()\n",
    "    stats = pstats.Stats(profiler)\n",
    "    stats.print_stats(0)\n",
    "    print(li_q2t)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try_stat()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultado \n",
    "[<br>\n",
    "('üôè', 7286), <br>\n",
    "('üòÇ', 3072), <br>\n",
    "('Ô∏è', 3061), <br>\n",
    "('üöú', 2972), <br>\n",
    "('‚úä', 2411), <br>\n",
    "('üåæ', 2363), <br>\n",
    "('üáÆ', 2096), <br>\n",
    "('üá≥', 2094), <br>\n",
    "('üèª', 2080), <br>\n",
    "('‚ù§', 1779)<br>\n",
    "]\n",
    "  \n",
    "(t+) se aprecia que el consumo de memoria en al menos 4 instrucciones es de ~1500MiB luego bajando a ~246MiB, el tiempo es de aproximados 9.2 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecucion2 optimizada para Memoria ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find file C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_5372\\3561448351.py\n",
      "Filename: c:\\Users\\Usuario\\Downloads\\challenge_DE\\src\\q2_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    17     96.8 MiB     96.8 MiB           1   @profile\n",
      "    18                                         def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
      "    19     96.9 MiB      0.1 MiB           1       with open(file_path, 'r') as f:\n",
      "    20    558.6 MiB   -340.8 MiB      117410           data = [[json.loads(line)['content']]  for line in f.readlines()]\n",
      "    21    158.0 MiB   -400.6 MiB           1       columnas = ['content']\n",
      "    22    160.1 MiB      2.1 MiB           1       pddf = pd.DataFrame(data, columns=columnas)\n",
      "    23                                             # elimino todo contenido que no sea un emoji\n",
      "    24    162.0 MiB     -2.4 MiB      234815       pddf['content'] = pddf['content'].apply(lambda x: ' '.join(re.findall(r'[\\U0001F300-\\U0001F5FF\\U0001F600-\\U0001F64F\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U00002702-\\U000027B0\\U000024C2-\\U0001F251\\U0001F004\\U0001F0CF\\U0001F170-\\U0001F251\\U0001F1E6-\\U0001F1FF]', x)))\n",
      "    25                                             # separo las celdas que tengan mas de un emoji en filas\n",
      "    26    173.9 MiB     11.8 MiB           1       pddf = pddf.assign(content=pddf['content'].str.split(' ')).explode('content').reset_index(drop=True)\n",
      "    27                                             # selecciono las filas que no sean vacias\n",
      "    28    174.0 MiB      0.2 MiB           1       pddf = pddf[pddf['content'] != ' ']\n",
      "    29    174.3 MiB      0.3 MiB           1       pddf = pddf[pddf['content'] != '']\n",
      "    30                                             \n",
      "    31                                             # count de emojis\n",
      "    32    175.4 MiB      1.1 MiB           1       df_topemoji = pddf.groupby('content').agg({'content': ['count']})\n",
      "    33    175.5 MiB      0.1 MiB           1       df_topemoji = df_topemoji.reset_index()\n",
      "    34                                             # rename de columnas\n",
      "    35    175.5 MiB      0.0 MiB           1       df_topemoji.columns = ['content','emoji_count']\n",
      "    36                                             # orderno desc\n",
      "    37    175.5 MiB      0.0 MiB           1       df_topemoji=df_topemoji.sort_values(by='emoji_count', ascending=False)\n",
      "    38                                             # selecciono las top10\n",
      "    39    175.5 MiB      0.0 MiB           1       df_topemoji = df_topemoji.head(10)\n",
      "    40                                             # dataframe a lista de tuplas\n",
      "    41    175.5 MiB      0.0 MiB           1       list_topemoji = list(df_topemoji.to_records(index=False))\n",
      "    42    175.5 MiB      0.0 MiB           1       return list_topemoji\n",
      "\n",
      "\n",
      "         2378215 function calls (2377859 primitive calls) in 13.667 seconds\n",
      "\n",
      "[('üôè', 7286), ('üòÇ', 3072), ('Ô∏è', 3061), ('üöú', 2972), ('‚úä', 2411), ('üåæ', 2363), ('üáÆ', 2096), ('üá≥', 2094), ('üèª', 2080), ('‚ù§', 1779)]\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler\n",
    "\n",
    "import q2_memory as q2m\n",
    "from memory_profiler import profile\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "@profile\n",
    "def try_stat():\n",
    "    profiler=cProfile.Profile()\n",
    "    profiler.enable()\n",
    "    li_q2m = q2m.q2_memory('../../farmers-protest-tweets-2021-2-4.json')\n",
    "    profiler.disable()\n",
    "    stats = pstats.Stats(profiler)\n",
    "    stats.print_stats(0)\n",
    "    print(li_q2m)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try_stat()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultado \n",
    "[<br>\n",
    "('üôè', 7286), <br>\n",
    "('üòÇ', 3072), <br>\n",
    "('Ô∏è', 3061), <br>\n",
    "('üöú', 2972), <br>\n",
    "('‚úä', 2411), <br>\n",
    "('üåæ', 2363), <br>\n",
    "('üáÆ', 2096), <br>\n",
    "('üá≥', 2094), <br>\n",
    "('üèª', 2080), <br>\n",
    "('‚ù§', 1779)<br>\n",
    "]\n",
    "  \n",
    "(m+) se aprecia que el consumo de memoria tiene como maximo 558MiB en una sola instruccion, luego bajando a 170MiB para la mayoria. el tiempo subio a aproximados ~13.6 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 3: \n",
    "El top 10 hist√≥rico de usuarios (username) m√°s influyentes en funci√≥n del conteo de las menciones (@) que registra cada uno de ellos.  \n",
    "\n",
    "**Supuesto1:** \n",
    "\n",
    "## Ejecucion3 optimizada para Tiempo ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "ERROR: Could not find file C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_1240\\3271878477.py\n",
      "Filename: c:\\Users\\Usuario\\Downloads\\challenge_DE\\src\\q3_time.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    17    309.4 MiB    309.4 MiB           1   @profile\n",
      "    18                                         def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
      "    19    309.4 MiB      0.0 MiB           1       pd.set_option('mode.chained_assignment', None)  #evita warning\n",
      "    20                                             # cargo el jsonl como dataframe pandas\n",
      "    21   1661.2 MiB   1351.8 MiB           1       pddf=pd.read_json(file_path, lines=True)\n",
      "    22                                             # trabajo solo con una columna, la que hace referencia al body del tweet\n",
      "    23   1497.5 MiB   -163.7 MiB           1       pddf=pddf[['content']]     \n",
      "    24                                             # selecciono solo filas que tengan al menos una mention\n",
      "    25   1499.6 MiB      2.1 MiB           1       pddf  = pddf[pddf['content'].str.extract(r'(?:[@]([a-zA-Z0-9_]+|$))', expand=False).notnull()]\n",
      "    26                                             # elimino todo contenido que no sea una mension\n",
      "    27   1499.9 MiB      0.3 MiB       76349       pddf['content'] = pddf['content'].apply(lambda x: ' '.join(re.findall(r'(?:[@]([a-zA-Z0-9_]+|$))', x)))\n",
      "    28                                             # separo las celdas que tengan mas de una mension en filas\n",
      "    29    328.0 MiB  -1171.9 MiB           1       pddf = pddf.assign(content=pddf['content'].str.split(' ')).explode('content').reset_index(drop=True)\n",
      "    30                                             # selecciono las filas que no sean vacias\n",
      "    31    328.3 MiB      0.3 MiB           1       pddf = pddf[~pddf['content'].isin([' ',''])]\n",
      "    32                                             \n",
      "    33                                             # count de emojis\n",
      "    34    328.6 MiB      0.3 MiB           1       df_topmention = pddf.groupby('content').agg({'content': ['count']})\n",
      "    35    328.6 MiB      0.0 MiB           1       df_topmention = df_topmention.reset_index()\n",
      "    36                                             # rename de columnas\n",
      "    37    328.6 MiB      0.0 MiB           1       df_topmention.columns = ['content','mention_count']\n",
      "    38                                             # orderno desc\n",
      "    39    328.9 MiB      0.4 MiB           1       df_topmention=df_topmention.sort_values(by='mention_count', ascending=False)\n",
      "    40                                             # selecciono las top10\n",
      "    41    328.9 MiB      0.0 MiB           1       df_topmention = df_topmention.head(10)\n",
      "    42                                             # dataframe a lista de tuplas\n",
      "    43    328.9 MiB      0.0 MiB           1       list_topmention = list(df_topmention.to_records(index=False))\n",
      "    44    328.9 MiB      0.0 MiB           1       return list_topmention\n",
      "\n",
      "\n",
      "         1108044 function calls (1107453 primitive calls) in 11.460 seconds\n",
      "\n",
      "[('narendramodi', 2261), ('Kisanektamorcha', 1836), ('RakeshTikaitBKU', 1641), ('PMOIndia', 1422), ('RahulGandhi', 1125), ('GretaThunberg', 1046), ('RaviSinghKA', 1015), ('rihanna', 972), ('UNHumanRights', 962), ('meenaharris', 925)]\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler\n",
    "\n",
    "import q3_time as q3t\n",
    "from memory_profiler import profile\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "@profile\n",
    "def try_stat():\n",
    "    profiler=cProfile.Profile()\n",
    "    profiler.enable()\n",
    "    li_q3t = q3t.q3_time('../../farmers-protest-tweets-2021-2-4.json')\n",
    "    profiler.disable()\n",
    "    stats = pstats.Stats(profiler)\n",
    "    stats.print_stats(0)\n",
    "    print(li_q3t)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try_stat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultado\n",
    "[<br>\n",
    "    ('narendramodi', 2261), <br>\n",
    "    ('Kisanektamorcha', 1836), <br>\n",
    "    ('RakeshTikaitBKU', 1641), <br>\n",
    "    ('PMOIndia', 1422), <br>\n",
    "    ('RahulGandhi', 1125), <br>\n",
    "    ('GretaThunberg', 1046), <br>\n",
    "    ('RaviSinghKA', 1015), <br>\n",
    "    ('rihanna', 972), <br>\n",
    "    ('UNHumanRights', 962), <br>\n",
    "    ('meenaharris', 925)<br>\n",
    "    ]\n",
    "\n",
    "(t+) se aprecia que el consumo de memoria en al menos 4 instrucciones es de ~1500MiB luego bajando a ~328MiB, el tiempo es de aproximados 11.4 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecucion3 optimizada para Memoria ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find file C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_9240\\462647421.py\n",
      "Filename: c:\\Users\\Usuario\\Downloads\\challenge_DE\\src\\q3_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    17     96.6 MiB     96.6 MiB           1   @profile\n",
      "    18                                         def q3_memory(file_path: str) -> List[Tuple[str, int]]:\n",
      "    19     96.6 MiB      0.0 MiB           1       with open(file_path, 'r') as f:\n",
      "    20    559.0 MiB   -348.3 MiB      117410           data = [[json.loads(line)['content']]  for line in f.readlines()]\n",
      "    21    154.0 MiB   -405.0 MiB           1       columnas = ['content']\n",
      "    22    156.1 MiB      2.1 MiB           1       pddf = pd.DataFrame(data, columns=columnas)\n",
      "    23                                             # trabajo solo con una columna, la que hace referencia al body del tweet\n",
      "    24    156.5 MiB      0.4 MiB           1       pddf=pddf[['content']]     \n",
      "    25                                             # elimino todo contenido que no sea un emoji\n",
      "    26    159.9 MiB      1.7 MiB      234815       pddf['content'] = pddf['content'].apply(lambda x: ' '.join(re.findall(r'(?:[@]([a-zA-Z0-9_]+|$))', x)))\n",
      "    27                                             # separo las celdas que tengan mas de un emoji en filas\n",
      "    28    177.4 MiB     17.5 MiB           1       pddf = pddf.assign(content=pddf['content'].str.split(' ')).explode('content').reset_index(drop=True)\n",
      "    29                                             # selecciono las filas que no sean vacias\n",
      "    30    177.6 MiB      0.2 MiB           1       pddf = pddf[pddf['content'] != ' ']\n",
      "    31    179.0 MiB      1.4 MiB           1       pddf = pddf[pddf['content'] != '']\n",
      "    32                                             \n",
      "    33                                             # count de emojis\n",
      "    34    181.6 MiB      2.6 MiB           1       df_topmention = pddf.groupby('content').agg({'content': ['count']})\n",
      "    35    181.7 MiB      0.1 MiB           1       df_topmention = df_topmention.reset_index()\n",
      "    36                                             # rename de columnas\n",
      "    37    181.7 MiB      0.0 MiB           1       df_topmention.columns = ['content','mention_count']\n",
      "    38                                             # orderno desc\n",
      "    39    182.0 MiB      0.3 MiB           1       df_topmention=df_topmention.sort_values(by='mention_count', ascending=False)\n",
      "    40                                             # selecciono las top10\n",
      "    41    182.0 MiB      0.0 MiB           1       df_topmention = df_topmention.head(10)\n",
      "    42                                             # dataframe a lista de tuplas\n",
      "    43    182.0 MiB      0.0 MiB           1       list_topmention = list(df_topmention.to_records(index=False))\n",
      "    44    182.0 MiB      0.0 MiB           1       return list_topmention\n",
      "\n",
      "\n",
      "         2378440 function calls (2378050 primitive calls) in 14.262 seconds\n",
      "\n",
      "[('narendramodi', 2261), ('Kisanektamorcha', 1836), ('RakeshTikaitBKU', 1641), ('PMOIndia', 1422), ('RahulGandhi', 1125), ('GretaThunberg', 1046), ('RaviSinghKA', 1015), ('rihanna', 972), ('UNHumanRights', 962), ('meenaharris', 925)]\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler\n",
    "\n",
    "import q3_memory as q3m\n",
    "from memory_profiler import profile\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "@profile\n",
    "def try_stat():\n",
    "    profiler=cProfile.Profile()\n",
    "    profiler.enable()\n",
    "    li_q3m = q3m.q3_memory('../../farmers-protest-tweets-2021-2-4.json')\n",
    "    profiler.disable()\n",
    "    stats = pstats.Stats(profiler)\n",
    "    stats.print_stats(0)\n",
    "    print(li_q3m)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try_stat()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultado\n",
    "[<br>\n",
    "    ('narendramodi', 2261), <br>\n",
    "    ('Kisanektamorcha', 1836), <br>\n",
    "    ('RakeshTikaitBKU', 1641), <br>\n",
    "    ('PMOIndia', 1422), <br>\n",
    "    ('RahulGandhi', 1125), <br>\n",
    "    ('GretaThunberg', 1046), <br>\n",
    "    ('RaviSinghKA', 1015), <br>\n",
    "    ('rihanna', 972), <br>\n",
    "    ('UNHumanRights', 962), <br>\n",
    "    ('meenaharris', 925)<br>\n",
    "    ]\n",
    "\n",
    "(m+) se aprecia que el consumo de memoria tiene como maximo 559MiB en una sola instruccion, luego bajando a 180MiB para la mayoria. el tiempo subio a aproximados ~14.2 seconds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
