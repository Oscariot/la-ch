{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1: \n",
    "Las top 10 fechas donde hay m√°s tweets. Mencionar el usuario (username) que m√°s publicaciones tiene por cada uno de esos d√≠as. \n",
    "\n",
    "**Supuesto1:** Para cumplir con lo solicitado, se trabaja el USERNAME como id unico representante de una cuenta, pero, como regla de negocio esto es incorrecto, ya que un USERNAME en twitter puede cambiar para una misma cuenta.\n",
    "\n",
    "## Ejecucion1 optimizada para Tiempo ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "ERROR: Could not find file C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_8176\\681458841.py\n",
      "Filename: c:\\Users\\Usuario\\Downloads\\challenge_DE\\src\\q1_time.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    16    154.0 MiB    154.0 MiB           1   @profile\n",
      "    17                                         def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
      "    18    154.0 MiB      0.0 MiB           1       resp = []\n",
      "    19    154.0 MiB      0.0 MiB           1       pd.set_option('mode.chained_assignment', None)  # Levantar una excepci√≥n\n",
      "    20   1675.6 MiB   1521.6 MiB           1       pddf=pd.read_json(file_path, lines=True)\n",
      "    21   1633.5 MiB    -42.1 MiB           1       pddf=pddf[['date','url','user']] \n",
      "    22   1635.3 MiB      1.7 MiB           1       pddf['date_fecha'] = pddf['date'].dt.date\n",
      "    23                                         \n",
      "    24   1636.3 MiB      1.0 MiB           1       df_topdates = pddf.groupby('date_fecha').agg({'url': ['count']})\n",
      "    25   1636.3 MiB      0.0 MiB           1       df_topdates.columns = ['url_count']\n",
      "    26   1636.3 MiB      0.0 MiB           1       df_topdates = df_topdates.reset_index()\n",
      "    27   1636.3 MiB      0.0 MiB           1       df_topdates=df_topdates.sort_values(by='url_count', ascending=False)\n",
      "    28   1636.3 MiB      0.0 MiB           1       df_topdates = df_topdates.head(10)\n",
      "    29                                         \n",
      "    30                                         \n",
      "    31   1639.9 MiB      0.0 MiB          11       for indice, fila in df_topdates.iterrows():\n",
      "    32   1639.8 MiB      2.2 MiB          10           df_topuser_xdate = pddf[pddf['date_fecha'] == fila['date_fecha']]\n",
      "    33   1639.8 MiB      0.3 MiB      198744           df_topuser_xdate['identificador'] = df_topuser_xdate['user'].apply(lambda x: x['username'])\n",
      "    34   1639.8 MiB      0.7 MiB          10           df_topuser_xdate = df_topuser_xdate.groupby('identificador').agg({'url': ['count']})\n",
      "    35   1639.8 MiB      0.0 MiB          10           df_topuser_xdate=df_topuser_xdate.reset_index()\n",
      "    36   1639.8 MiB      0.0 MiB          10           df_topuser_xdate.columns = ['identificador','url_count']\n",
      "    37   1639.9 MiB      0.4 MiB          10           df_topuser_xdate=df_topuser_xdate.sort_values(by='url_count', ascending=False)\n",
      "    38   1639.9 MiB      0.0 MiB          10           df_topuser_xdate = df_topuser_xdate.head(1)\n",
      "    39   1639.9 MiB      0.0 MiB          10           resp.append((fila['date_fecha'],df_topuser_xdate['identificador'].values[0])) #\n",
      "    40                                         \n",
      "    41   1639.9 MiB      0.0 MiB           1       return resp\n",
      "\n",
      "\n",
      "         672858 function calls (671326 primitive calls) in 10.129 seconds\n",
      "\n",
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler\n",
    "\n",
    "import q1_time as q1t\n",
    "from memory_profiler import profile\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "@profile\n",
    "def try_stat():\n",
    "    profiler=cProfile.Profile()\n",
    "    profiler.enable()\n",
    "    li_q1t = q1t.q1_time('./farmers-protest-tweets-2021-2-4.json')\n",
    "    profiler.disable()\n",
    "    stats = pstats.Stats(profiler)\n",
    "    stats.print_stats(0)\n",
    "    print(li_q1t)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try_stat()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultado\n",
    "[<br>\n",
    "  (datetime.date(2021, 2, 12), 'RanbirS00614606'), <br>\n",
    "  (datetime.date(2021, 2, 13), 'MaanDee08215437'),<br>\n",
    "  (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), <br>\n",
    "  (datetime.date(2021, 2, 16), 'jot__b'), <br>\n",
    "  (datetime.date(2021, 2, 14), 'rebelpacifist'), <br>\n",
    "  (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), <br>\n",
    "  (datetime.date(2021, 2, 15), 'jot__b'), <br>\n",
    "  (datetime.date(2021, 2, 20), 'MangalJ23056160'), <br>\n",
    "  (datetime.date(2021, 2, 23), 'Surrypuria'), <br>\n",
    "  (datetime.date(2021, 2, 19), 'Preetm91')<br>\n",
    "  ]<br>\n",
    " \n",
    "(t+) se aprecia que el consumo de memoria en cada instruccion es de ~1640MiB para casi todas las instrucciones del primer y segundo bloque, el tiempo es de  aproximados 10 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecucion1 optimizada para Memoria ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "ERROR: Could not find file C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_8176\\4294011426.py\n",
      "Filename: c:\\Users\\Usuario\\Downloads\\challenge_DE\\src\\q1_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    17    157.4 MiB    157.4 MiB           1   @profile\n",
      "    18                                         def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
      "    19    157.4 MiB      0.0 MiB           1       resp = []\n",
      "    20    157.4 MiB      0.0 MiB           1       pd.set_option('mode.chained_assignment', None)  # Levantar una excepci√≥n\n",
      "    21    157.4 MiB      0.0 MiB           1       with open(file_path, 'r') as f:\n",
      "    22    570.8 MiB -15426.6 MiB      117410           data = [[json.loads(line)['url'], pd.to_datetime(json.loads(line)['date']), json.loads(line)['user']['username']]  for line in f.readlines()]\n",
      "    23    438.5 MiB   -132.3 MiB           1       columnas = ['url', 'date', 'identificador']\n",
      "    24    440.4 MiB      1.9 MiB           1       pddf = pd.DataFrame(data, columns=columnas)\n",
      "    25    444.1 MiB      3.7 MiB           1       pddf['date_fecha'] = pddf['date'].dt.date\n",
      "    26                                         \n",
      "    27    444.2 MiB      0.1 MiB           1       df_topdates = pddf.groupby('date_fecha').agg({'url': ['count']})\n",
      "    28    444.2 MiB      0.0 MiB           1       df_topdates.columns = ['url_count']\n",
      "    29    444.2 MiB      0.0 MiB           1       df_topdates = df_topdates.reset_index()\n",
      "    30    444.2 MiB      0.0 MiB           1       df_topdates=df_topdates.sort_values(by='url_count', ascending=False)\n",
      "    31    444.2 MiB      0.0 MiB           1       df_topdates = df_topdates.head(10)\n",
      "    32                                         \n",
      "    33    444.2 MiB      0.0 MiB          11       for indice, fila in df_topdates.iterrows():\n",
      "    34    444.2 MiB    -27.3 MiB          10           df_topuser_xdate = pddf[pddf['date_fecha'] == fila['date_fecha']]\n",
      "    35                                                 #df_topuser_xdate['identificador'] = df_topuser_xdate['user'].apply(lambda x: x['username'])\n",
      "    36    441.2 MiB    -30.3 MiB          10           df_topuser_xdate = df_topuser_xdate.groupby('identificador').agg({'url': ['count']})\n",
      "    37    441.2 MiB      0.0 MiB          10           df_topuser_xdate=df_topuser_xdate.reset_index()\n",
      "    38    441.2 MiB      0.0 MiB          10           df_topuser_xdate.columns = ['identificador','url_count']\n",
      "    39    441.2 MiB      0.0 MiB          10           df_topuser_xdate=df_topuser_xdate.sort_values(by='url_count', ascending=False)\n",
      "    40    441.2 MiB      0.0 MiB          10           df_topuser_xdate = df_topuser_xdate.head(1)\n",
      "    41    441.2 MiB      0.0 MiB          10           resp.append((fila['date_fecha'],df_topuser_xdate['identificador'].values[0])) #\n",
      "    42                                         \n",
      "    43    441.2 MiB     -3.0 MiB           1       return resp\n",
      "\n",
      "\n",
      "         144211904 function calls (144093254 primitive calls) in 403.207 seconds\n",
      "\n",
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler\n",
    "\n",
    "import q1_memory as q1m\n",
    "from memory_profiler import profile\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "@profile\n",
    "def try_stat():\n",
    "    profiler=cProfile.Profile()\n",
    "    profiler.enable()\n",
    "    li_q1m = q1m.q1_memory('./farmers-protest-tweets-2021-2-4.json')\n",
    "    profiler.disable()\n",
    "    stats = pstats.Stats(profiler)\n",
    "    stats.print_stats(0)\n",
    "    print(li_q1m)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try_stat()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultado \n",
    "[<br>\n",
    "  (datetime.date(2021, 2, 12), 'RanbirS00614606'), <br>\n",
    "  (datetime.date(2021, 2, 13), 'MaanDee08215437'),<br>\n",
    "  (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), <br>\n",
    "  (datetime.date(2021, 2, 16), 'jot__b'), <br>\n",
    "  (datetime.date(2021, 2, 14), 'rebelpacifist'), <br>\n",
    "  (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), <br>\n",
    "  (datetime.date(2021, 2, 15), 'jot__b'), <br>\n",
    "  (datetime.date(2021, 2, 20), 'MangalJ23056160'), <br>\n",
    "  (datetime.date(2021, 2, 23), 'Surrypuria'), <br>\n",
    "  (datetime.date(2021, 2, 19), 'Preetm91')<br>\n",
    "  ]<br>\n",
    "  \n",
    "(m+) se aprecia que el consumo de memoria en cada instruccion del primer y segundo bloque es de aproximados ~440MiB. y en consecuencia, el tiempo subio considerablemente a aproximados ~403 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2: \n",
    "Los top 10 emojis m√°s usados con su respectivo conteo. \n",
    "\n",
    "**Supuesto1:** No tengo una definicion clara de que es un emoji, ya que tecnicamente un emoji es un caracter unicode representado por un \\u*, por lo que bajo esa definicion se trabajo la solucion.\n",
    "\n",
    "## Ejecucion2 optimizada para Tiempo ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "ERROR: Could not find file C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_8176\\1025412768.py\n",
      "Filename: c:\\Users\\Usuario\\Downloads\\challenge_DE\\src\\q2_time.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    17    430.2 MiB    430.2 MiB           1   @profile\n",
      "    18                                         def q2_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
      "    19    430.2 MiB      0.0 MiB           1       pd.set_option('mode.chained_assignment', None)  #evita warning\n",
      "    20                                             #cargo el jsonl como dataframe pandas\n",
      "    21   1665.7 MiB   1235.5 MiB           1       pddf=pd.read_json(file_path, lines=True)\n",
      "    22                                             #trabajo solo con una columna, la que hace referencia al body del tweet\n",
      "    23   1500.9 MiB   -164.8 MiB           1       pddf=pddf[['content']]     \n",
      "    24                                             # selecciono solo las filas que tengan al menos un emoji\n",
      "    25   1502.7 MiB      1.8 MiB           1       pddf = pddf[pddf['content'].str.contains(r'[\\U0001F300-\\U0001F5FF\\U0001F600-\\U0001F64F\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U00002702-\\U000027B0\\U000024C2-\\U0001F251\\U0001F004\\U0001F0CF\\U0001F170-\\U0001F251\\U0001F1E6-\\U0001F1FF]', regex=True)]\n",
      "    26                                             # elimino todo contenido que no sea un emoji\n",
      "    27   1502.8 MiB      0.1 MiB       33901       pddf['content'] = pddf['content'].apply(lambda x: ' '.join(re.findall(r'[\\U0001F300-\\U0001F5FF\\U0001F600-\\U0001F64F\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U00002702-\\U000027B0\\U000024C2-\\U0001F251\\U0001F004\\U0001F0CF\\U0001F170-\\U0001F251\\U0001F1E6-\\U0001F1FF]', x)))\n",
      "    28                                             # separo las celdas que tengan mas de un emoji en filas\n",
      "    29    246.7 MiB  -1256.2 MiB           1       pddf = pddf.assign(content=pddf['content'].str.split(' ')).explode('content').reset_index(drop=True)\n",
      "    30                                             # selecciono las filas que no sean vacias\n",
      "    31    246.7 MiB      0.0 MiB           1       pddf = pddf[pddf['content'] != ' ']\n",
      "    32                                             \n",
      "    33                                             # count de emojis\n",
      "    34    246.7 MiB      0.1 MiB           1       df_topemoji = pddf.groupby('content').agg({'content': ['count']})\n",
      "    35    246.7 MiB      0.0 MiB           1       df_topemoji = df_topemoji.reset_index()\n",
      "    36                                             # rename de columnas\n",
      "    37    246.7 MiB      0.0 MiB           1       df_topemoji.columns = ['content','emoji_count']\n",
      "    38                                             # orderno desc\n",
      "    39    246.7 MiB      0.0 MiB           1       df_topemoji=df_topemoji.sort_values(by='emoji_count', ascending=False)\n",
      "    40                                             # selecciono las top10\n",
      "    41    246.7 MiB      0.0 MiB           1       df_topemoji = df_topemoji.head(10)\n",
      "    42                                             # dataframe a lista de tuplas\n",
      "    43    246.7 MiB      0.0 MiB           1       list_topemoji = list(df_topemoji.to_records(index=False))\n",
      "    44    246.7 MiB      0.0 MiB           1       return list_topemoji\n",
      "\n",
      "\n",
      "         905398 function calls (904779 primitive calls) in 9.277 seconds\n",
      "\n",
      "[('üôè', 7286), ('üòÇ', 3072), ('Ô∏è', 3061), ('üöú', 2972), ('‚úä', 2411), ('üåæ', 2363), ('üáÆ', 2096), ('üá≥', 2094), ('üèª', 2080), ('‚ù§', 1779)]\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler\n",
    "\n",
    "import q2_time as q2t\n",
    "from memory_profiler import profile\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "@profile\n",
    "def try_stat():\n",
    "    profiler=cProfile.Profile()\n",
    "    profiler.enable()\n",
    "    li_q2t = q2t.q2_time('./farmers-protest-tweets-2021-2-4.json')\n",
    "    profiler.disable()\n",
    "    stats = pstats.Stats(profiler)\n",
    "    stats.print_stats(0)\n",
    "    print(li_q2t)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try_stat()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultado \n",
    "[<br>\n",
    "('üôè', 7286), <br>\n",
    "('üòÇ', 3072), <br>\n",
    "('Ô∏è', 3061), <br>\n",
    "('üöú', 2972), <br>\n",
    "('‚úä', 2411), <br>\n",
    "('üåæ', 2363), <br>\n",
    "('üáÆ', 2096), <br>\n",
    "('üá≥', 2094), <br>\n",
    "('üèª', 2080), <br>\n",
    "('‚ù§', 1779)<br>\n",
    "]\n",
    "  \n",
    "(t+) se aprecia que el consumo de memoria en al menos 4 instrucciones es de ~1500MiB luego bajando a ~246MiB, el tiempo es de aproximados 9.2 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecucion2 optimizada para Memoria ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "ERROR: Could not find file C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_8176\\3497146961.py\n",
      "Filename: c:\\Users\\Usuario\\Downloads\\challenge_DE\\src\\q2_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    18    236.2 MiB    236.2 MiB           1   @profile\n",
      "    19                                         def q2_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
      "    20    236.2 MiB      0.0 MiB           1       with open(file_path, 'r') as f:\n",
      "    21    640.6 MiB -1166168.4 MiB      117410           data = [[json.loads(line)['content']]  for line in f.readlines()]\n",
      "    22    555.0 MiB    -85.6 MiB           1       columnas = ['content']\n",
      "    23    554.4 MiB     -0.6 MiB           1       pddf = pd.DataFrame(data, columns=columnas)\n",
      "    24                                             # elimino todo contenido que no sea un emoji\n",
      "    25    556.2 MiB      1.8 MiB      234815       pddf['content'] = pddf['content'].apply(lambda x: ' '.join(re.findall(r'[\\U0001F300-\\U0001F5FF\\U0001F600-\\U0001F64F\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U00002702-\\U000027B0\\U000024C2-\\U0001F251\\U0001F004\\U0001F0CF\\U0001F170-\\U0001F251\\U0001F1E6-\\U0001F1FF]', x)))\n",
      "    26                                             # separo las celdas que tengan mas de un emoji en filas\n",
      "    27    558.3 MiB      2.1 MiB           1       pddf = pddf.assign(content=pddf['content'].str.split(' ')).explode('content').reset_index(drop=True)\n",
      "    28                                             # selecciono las filas que no sean vacias\n",
      "    29    558.3 MiB      0.0 MiB           1       pddf = pddf[pddf['content'] != ' ']\n",
      "    30                                             \n",
      "    31                                             # count de emojis\n",
      "    32    558.3 MiB      0.0 MiB           1       df_topemoji = pddf.groupby('content').agg({'content': ['count']})\n",
      "    33    558.3 MiB      0.0 MiB           1       df_topemoji = df_topemoji.reset_index()\n",
      "    34                                             # rename de columnas\n",
      "    35    558.3 MiB      0.0 MiB           1       df_topemoji.columns = ['content','emoji_count']\n",
      "    36                                             # orderno desc\n",
      "    37    558.3 MiB      0.0 MiB           1       df_topemoji=df_topemoji.sort_values(by='emoji_count', ascending=False)\n",
      "    38                                             # selecciono las top10\n",
      "    39    558.3 MiB      0.0 MiB           1       df_topemoji = df_topemoji.head(10)\n",
      "    40                                             # dataframe a lista de tuplas\n",
      "    41    558.3 MiB      0.0 MiB           1       list_topemoji = list(df_topemoji.to_records(index=False))\n",
      "    42    558.3 MiB      0.0 MiB           1       return list_topemoji\n",
      "\n",
      "\n",
      "         2232748 function calls (2232547 primitive calls) in 11.611 seconds\n",
      "\n",
      "[('', 100457), ('üôè', 7286), ('üòÇ', 3072), ('Ô∏è', 3061), ('üöú', 2972), ('‚úä', 2411), ('üåæ', 2363), ('üáÆ', 2096), ('üá≥', 2094), ('üèª', 2080)]\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler\n",
    "\n",
    "import q2_memory as q2m\n",
    "from memory_profiler import profile\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "@profile\n",
    "def try_stat():\n",
    "    profiler=cProfile.Profile()\n",
    "    profiler.enable()\n",
    "    li_q2m = q2m.q2_memory('./farmers-protest-tweets-2021-2-4.json')\n",
    "    profiler.disable()\n",
    "    stats = pstats.Stats(profiler)\n",
    "    stats.print_stats(0)\n",
    "    print(li_q2m)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try_stat()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultado \n",
    "[<br>\n",
    "('üôè', 7286), <br>\n",
    "('üòÇ', 3072), <br>\n",
    "('Ô∏è', 3061), <br>\n",
    "('üöú', 2972), <br>\n",
    "('‚úä', 2411), <br>\n",
    "('üåæ', 2363), <br>\n",
    "('üáÆ', 2096), <br>\n",
    "('üá≥', 2094), <br>\n",
    "('üèª', 2080), <br>\n",
    "('‚ù§', 1779)<br>\n",
    "]\n",
    "  \n",
    "(m+) se aprecia que el consumo de memoria en cada instruccion es tiene como maximo 640MiB en una sola instruccion, luego bajando a 558MiB para la mayoria. el tiempo subio a aproximados ~11.6 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 3: \n",
    "El top 10 hist√≥rico de usuarios (username) m√°s influyentes en funci√≥n del conteo de las menciones (@) que registra cada uno de ellos.  \n",
    "\n",
    "**Supuesto1:** \n",
    "\n",
    "## Ejecucion3 optimizada para Tiempo ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "ERROR: Could not find file C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_8176\\565335560.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\Downloads\\challenge_DE\\src\\q3_time.py:25: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  pddf = pddf[pddf['content'].str.contains(r'(?:[@]([a-zA-Z0-9_]+|$))', regex=True)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: c:\\Users\\Usuario\\Downloads\\challenge_DE\\src\\q3_time.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    17    163.7 MiB    163.7 MiB           1   @profile\n",
      "    18                                         def q3_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
      "    19    163.7 MiB      0.0 MiB           1       pd.set_option('mode.chained_assignment', None)  #evita warning\n",
      "    20                                             #cargo el jsonl como dataframe pandas\n",
      "    21   1958.3 MiB   1794.5 MiB           1       pddf=pd.read_json(file_path, lines=True)\n",
      "    22                                             #trabajo solo con una columna, la que hace referencia al body del tweet\n",
      "    23   1901.1 MiB    -57.2 MiB           1       pddf=pddf[['content']]     \n",
      "    24                                             # selecciono solo las filas que tengan al menos un emoji\n",
      "    25   1899.4 MiB     -1.7 MiB           1       pddf = pddf[pddf['content'].str.contains(r'(?:[@]([a-zA-Z0-9_]+|$))', regex=True)]\n",
      "    26                                             # elimino todo contenido que no sea un emoji\n",
      "    27   1899.4 MiB      0.0 MiB       76349       pddf['content'] = pddf['content'].apply(lambda x: ' '.join(re.findall(r'(?:[@]([a-zA-Z0-9_]+|$))', x)))\n",
      "    28                                             # separo las celdas que tengan mas de un emoji en filas\n",
      "    29    659.9 MiB  -1239.5 MiB           1       pddf = pddf.assign(content=pddf['content'].str.split(' ')).explode('content').reset_index(drop=True)\n",
      "    30                                             # selecciono las filas que no sean vacias\n",
      "    31    659.9 MiB      0.0 MiB           1       pddf = pddf[pddf['content'] != ' ']\n",
      "    32                                             \n",
      "    33                                             # count de emojis\n",
      "    34    660.0 MiB      0.0 MiB           1       df_topmention = pddf.groupby('content').agg({'content': ['count']})\n",
      "    35    660.0 MiB      0.0 MiB           1       df_topmention = df_topmention.reset_index()\n",
      "    36                                             # rename de columnas\n",
      "    37    660.0 MiB      0.0 MiB           1       df_topmention.columns = ['content','mention_count']\n",
      "    38                                             # orderno desc\n",
      "    39    660.0 MiB      0.0 MiB           1       df_topmention=df_topmention.sort_values(by='mention_count', ascending=False)\n",
      "    40                                             # selecciono las top10\n",
      "    41    660.0 MiB      0.0 MiB           1       df_topmention = df_topmention.head(10)\n",
      "    42                                             # dataframe a lista de tuplas\n",
      "    43    660.0 MiB      0.0 MiB           1       list_topmention = list(df_topmention.to_records(index=False))\n",
      "    44    660.0 MiB      0.0 MiB           1       return list_topmention\n",
      "\n",
      "\n",
      "         1075448 function calls (1074848 primitive calls) in 9.591 seconds\n",
      "\n",
      "[('narendramodi', 2261), ('Kisanektamorcha', 1836), ('RakeshTikaitBKU', 1641), ('PMOIndia', 1422), ('RahulGandhi', 1125), ('GretaThunberg', 1046), ('RaviSinghKA', 1015), ('rihanna', 972), ('UNHumanRights', 962), ('meenaharris', 925)]\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler\n",
    "\n",
    "import q3_time as q3t\n",
    "from memory_profiler import profile\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "@profile\n",
    "def try_stat():\n",
    "    profiler=cProfile.Profile()\n",
    "    profiler.enable()\n",
    "    li_q3t = q3t.q3_time('./farmers-protest-tweets-2021-2-4.json')\n",
    "    profiler.disable()\n",
    "    stats = pstats.Stats(profiler)\n",
    "    stats.print_stats(0)\n",
    "    print(li_q3t)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try_stat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultado\n",
    "[<br>\n",
    "    ('narendramodi', 2261), <br>\n",
    "    ('Kisanektamorcha', 1836), <br>\n",
    "    ('RakeshTikaitBKU', 1641), <br>\n",
    "    ('PMOIndia', 1422), <br>\n",
    "    ('RahulGandhi', 1125), <br>\n",
    "    ('GretaThunberg', 1046), <br>\n",
    "    ('RaviSinghKA', 1015), <br>\n",
    "    ('rihanna', 972), <br>\n",
    "    ('UNHumanRights', 962), <br>\n",
    "    ('meenaharris', 925)<br>\n",
    "    ]\n",
    "\n",
    "(t+) se aprecia que el consumo de memoria en al menos 4 instrucciones es de ~1900MiB luego bajando a ~660MiB, el tiempo es de aproximados 9.5 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecucion3 optimizada para Memoria ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "ERROR: Could not find file C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_8176\\3965048329.py\n",
      "Filename: c:\\Users\\Usuario\\Downloads\\challenge_DE\\src\\q3_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    18    649.5 MiB    649.5 MiB           1   @profile\n",
      "    19                                         def q3_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
      "    20    649.5 MiB      0.0 MiB           1       with open(file_path, 'r') as f:\n",
      "    21    703.9 MiB -765573.5 MiB      117410           data = [[json.loads(line)['content']]  for line in f.readlines()]\n",
      "    22    641.8 MiB    -62.1 MiB           1       columnas = ['content']\n",
      "    23    642.7 MiB      0.9 MiB           1       pddf = pd.DataFrame(data, columns=columnas)\n",
      "    24                                             #trabajo solo con una columna, la que hace referencia al body del tweet\n",
      "    25    643.6 MiB      0.9 MiB           1       pddf=pddf[['content']]     \n",
      "    26                                             # elimino todo contenido que no sea un emoji\n",
      "    27    644.5 MiB      0.9 MiB      234815       pddf['content'] = pddf['content'].apply(lambda x: ' '.join(re.findall(r'(?:[@]([a-zA-Z0-9_]+|$))', x)))\n",
      "    28                                             # separo las celdas que tengan mas de un emoji en filas\n",
      "    29    645.9 MiB      1.4 MiB           1       pddf = pddf.assign(content=pddf['content'].str.split(' ')).explode('content').reset_index(drop=True)\n",
      "    30                                             # selecciono las filas que no sean vacias\n",
      "    31    645.9 MiB      0.0 MiB           1       pddf = pddf[pddf['content'] != ' ']\n",
      "    32                                             \n",
      "    33                                             # count de emojis\n",
      "    34    645.9 MiB      0.0 MiB           1       df_topmention = pddf.groupby('content').agg({'content': ['count']})\n",
      "    35    645.9 MiB      0.0 MiB           1       df_topmention = df_topmention.reset_index()\n",
      "    36                                             # rename de columnas\n",
      "    37    645.9 MiB      0.0 MiB           1       df_topmention.columns = ['content','mention_count']\n",
      "    38                                             # orderno desc\n",
      "    39    645.9 MiB      0.0 MiB           1       df_topmention=df_topmention.sort_values(by='mention_count', ascending=False)\n",
      "    40                                             # selecciono las top10\n",
      "    41    645.9 MiB      0.0 MiB           1       df_topmention = df_topmention.head(10)\n",
      "    42                                             # dataframe a lista de tuplas\n",
      "    43    645.9 MiB      0.0 MiB           1       list_topmention = list(df_topmention.to_records(index=False))\n",
      "    44    645.9 MiB      0.0 MiB           1       return list_topmention\n",
      "\n",
      "\n",
      "         2233520 function calls (2233304 primitive calls) in 11.398 seconds\n",
      "\n",
      "[('', 79253), ('narendramodi', 2261), ('Kisanektamorcha', 1836), ('RakeshTikaitBKU', 1641), ('PMOIndia', 1422), ('RahulGandhi', 1125), ('GretaThunberg', 1046), ('RaviSinghKA', 1015), ('rihanna', 972), ('UNHumanRights', 962)]\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler\n",
    "\n",
    "import q3_memory as q3m\n",
    "from memory_profiler import profile\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "@profile\n",
    "def try_stat():\n",
    "    profiler=cProfile.Profile()\n",
    "    profiler.enable()\n",
    "    li_q3m = q3m.q3_memory('./farmers-protest-tweets-2021-2-4.json')\n",
    "    profiler.disable()\n",
    "    stats = pstats.Stats(profiler)\n",
    "    stats.print_stats(0)\n",
    "    print(li_q3m)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try_stat()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultado\n",
    "[<br>\n",
    "    ('narendramodi', 2261), <br>\n",
    "    ('Kisanektamorcha', 1836), <br>\n",
    "    ('RakeshTikaitBKU', 1641), <br>\n",
    "    ('PMOIndia', 1422), <br>\n",
    "    ('RahulGandhi', 1125), <br>\n",
    "    ('GretaThunberg', 1046), <br>\n",
    "    ('RaviSinghKA', 1015), <br>\n",
    "    ('rihanna', 972), <br>\n",
    "    ('UNHumanRights', 962), <br>\n",
    "    ('meenaharris', 925)<br>\n",
    "    ]\n",
    "\n",
    "(m+) se aprecia que el consumo de memoria tiene como maximo 650MiB en una sola instruccion, luego bajando a 150MiB para la mayoria. el tiempo subio a aproximados ~11.3 seconds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
